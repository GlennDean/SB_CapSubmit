{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6c021d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:40:13  |\n",
      "- - - - - - - - - - - - - - -\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "\n",
      "Sample of the 'Books and Book-Titles' dataframe\n",
      "\n",
      "      book_id                                              title\n",
      "849       850  Mr. Penumbra's 24-Hour Bookstore (Mr. Penumbra...\n",
      "8401     8402               Archangel's Blade (Guild Hunter, #4)\n",
      "4716     4717  The Shunning (The Heritage of Lancaster County...\n",
      "4455     4456                      Fallen in Love (Fallen, #3.5)\n",
      "3938     3939                                     History of Art\n",
      "\n",
      "\n",
      "Sample of the 'User-ID ratings of Book-ID' dataframe\n",
      "\n",
      "         user_id  book_id  rating\n",
      "1099208    16770     4994       5\n",
      "796026     12991       53       4\n",
      "4415989    32567     3138       3\n",
      "2472504     7042       48       5\n",
      "3342606    28007      172       4\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "Shape User-Ratings unfiltered:\t(5976479, 3)\n",
      "Shape User-Ratings filtered:\t(4508993, 3)\n",
      "\n",
      " unique user_id counts: 36199\n",
      "\n",
      " unique book_id counts: 9466\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "df_train shape =  (4408993, 3) df_test shape =  (100000, 3)\n",
      "sample of df_train follows:\n",
      "         user_id  book_id  rating\n",
      "2330920    19344      112       1\n",
      "3844403    44243      222       3\n",
      "2636955    34025      999       4\n",
      "2406501     3623      634       4\n",
      "194130      4929     1847       5\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "The 'Two Features' that will be fed into the ANN (prior to scaling) follows:\n",
      "\n",
      "[[    0     0]\n",
      " [    1     1]\n",
      " [    2     2]\n",
      " ...\n",
      " [ 2950   534]\n",
      " [ 4609  1460]\n",
      " [10788    68]]\n",
      "\n",
      "The 'Two Features' that will be fed into the ANN (after scaling) follows:\n",
      "\n",
      "[[-1.71924742 -1.03848204]\n",
      " [-1.71915137 -1.03805213]\n",
      " [-1.71905532 -1.03762222]\n",
      " ...\n",
      " [-1.4358986  -0.8089092 ]\n",
      " [-1.27655091 -0.41081098]\n",
      " [-0.68305521 -1.00924805]]\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:40:19  |\n",
      "- - - - - - - - - - - - - - -\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "# To create deep learning models\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "#from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def PrintCurrentTime():\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"\\n- - - - - - - - - - - - - - -\")\n",
    "    print(\"| Current Time = \", current_time,\" |\")\n",
    "    print(\"- - - - - - - - - - - - - - -\")\n",
    "    \n",
    "#----------------------------------------------------------------------#\n",
    "PrintCurrentTime()\n",
    "\n",
    "myModel = keras.Sequential([\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(32, activation='relu'),\n",
    "      layers.Dense(5,activation='softmax')\n",
    "  ])\n",
    "\n",
    "myModel.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "# Load the 'Books and Book-Titles' \n",
    "df_books_and_titles = pd.read_csv('dataset\\\\books.csv')\n",
    "df_books_and_titles = df_books_and_titles[['book_id','title']]\n",
    "print(\"\\n\\nSample of the 'Books and Book-Titles' dataframe\\n\")\n",
    "print(df_books_and_titles.sample(5))\n",
    "\n",
    "# Create a dictionary mapping 'book_id' to 'title'\n",
    "di_book_title = {}\n",
    "for i in range(len(df_books_and_titles)):\n",
    "    bk_id = df_books_and_titles.loc[i,'book_id']\n",
    "    title = df_books_and_titles.loc[i,'title']\n",
    "    di_book_title[bk_id] = title\n",
    "\n",
    "rev_di_book_title = {value : key for (key, value) in di_book_title.items()} # 'title' to 'book_id'\n",
    "\n",
    "# Load the 'User-ID ratings of Book-ID'\n",
    "df_user_book_ratings = pd.read_csv('dataset\\\\ratings-books.csv')\n",
    "df_user_book_ratings = shuffle(df_user_book_ratings)\n",
    "\n",
    "print(\"\\n\\nSample of the 'User-ID ratings of Book-ID' dataframe\\n\")\n",
    "print(df_user_book_ratings.sample(5))\n",
    "\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "# Filter sparse books\n",
    "min_book_ratings = 100\n",
    "filter_books = (df_user_book_ratings['book_id'].value_counts()>min_book_ratings)\n",
    "filter_books = filter_books[filter_books].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 100\n",
    "filter_users = (df_user_book_ratings['user_id'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "# Actual filtering\n",
    "df_filtered = df_user_book_ratings[(df_user_book_ratings['book_id'].isin(filter_books)) & \\\n",
    "                                   (df_user_book_ratings['user_id'].isin(filter_users))]\n",
    "\n",
    "del filter_books, filter_users, min_book_ratings, min_user_ratings\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df_user_book_ratings.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filtered.shape))\n",
    "\n",
    "print(\"\\n unique user_id counts:\", len(df_filtered.groupby(['user_id']).count()))\n",
    "print(\"\\n unique book_id counts:\", len(df_filtered.groupby(['book_id']).count()))\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "# Testingsize\n",
    "n = 100000\n",
    "\n",
    "# Split train- & testset\n",
    "df_train = df_filtered[:-n]\n",
    "df_test = df_filtered[-n:]\n",
    "print(\"df_train shape = \",df_train.shape, \"df_test shape = \",df_test.shape)\n",
    "print(\"sample of df_train follows:\")\n",
    "print(df_train.sample(5))\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "# Create user and movie-id mapping to convert to numbers\n",
    "user_id_mapping = {id:i for i, id in enumerate(df_filtered['user_id'].unique())}\n",
    "#print(user_id_mapping) # user_id_mapping is a dictionary that simply re-enumerates userIDs to sequential numbers 0,1,2,3\n",
    "book_id_mapping = {id:i for i, id in enumerate(df_filtered['book_id'].unique())}\n",
    "\n",
    "# get the reverse of these mappings\n",
    "rev_user_id_mapping = {value : key for (key, value) in user_id_mapping.items()}\n",
    "rev_book_id_mapping = {value : key for (key, value) in book_id_mapping.items()}\n",
    "\n",
    "book_names = [name for idx,name in di_book_title.items()]\n",
    "book_names.sort()\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "# use dataframe map function to map users & movies to mapped ids based on above mapping\n",
    "train_user_data = df_train['user_id'].map(user_id_mapping)\n",
    "train_book_data = df_train['book_id'].map(book_id_mapping)\n",
    "#print(\"\\ntype(train_user_data) = \",type(train_user_data))\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "data_feed_into_ann = pd.DataFrame({\"user_id\":train_user_data,\"book_id\":train_book_data})\n",
    "#print(\"\\ntype(data_feed_into_ann) = \",type(data_feed_into_ann))\n",
    "#print(\"sample of data_feed_into_ann follows:\")\n",
    "#print(data_feed_into_ann.sample(10))\n",
    "\n",
    "data_feed_into_ann_values = data_feed_into_ann.values\n",
    "print(\"\\nThe 'Two Features' that will be fed into the ANN (prior to scaling) follows:\\n\")\n",
    "print(data_feed_into_ann_values)\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "data_feed_into_ann_values_scaled = sc.fit_transform(data_feed_into_ann_values)\n",
    "#print(\"\\ntype(data_feed_into_ann_values_scaled) = \",type(data_feed_into_ann_values_scaled))\n",
    "print(\"\\nThe 'Two Features' that will be fed into the ANN (after scaling) follows:\\n\")\n",
    "print(data_feed_into_ann_values_scaled)\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "PrintCurrentTime()\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78cec701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[' Angels (Walsh Family, #3)', '\"حكايات فرغلي المستكاوي \"حكايتى مع كفر السحلاوية', '#GIRLBOSS', \"'Salem's Lot\", \"'Salem's Lot\", \"'Tis (Frank McCourt, #2)\", '1,000 Places to See Before You Die', '1/4 جرام', '10% Happier: How I Tamed the Voice in My Head, Reduced Stress Without Losing My Edge, and Found Self-Help That Actually Works', '100 Bullets, Vol. 1: First Shot, Last Call', '100 Love Sonnets', '100 Selected Poems', \"10th Anniversary (Women's Murder Club, #10)\", '11 Birthdays (Willow Falls, #1)', '11/22/63', \"11th Hour (Women's Murder Club, #11)\", \"12th of Never (Women's Murder Club, #12)\", '13 Gifts (Willow Falls, #3)', '13 Hours: The Inside Account of What Really Happened In Benghazi', '13 Little Blue Envelopes (Little Blue Envelope, #1)', '14', '1421: The Year China Discovered America', '1491: New Revelations of the Americas Before Columbus', '1493: Uncovering the New World Columbus Created', '14th Deadly Sin (Women’s Murder Club, #14)', \"15th Affair (Women's Murder Club #15)\", '16 Lighthouse Road (Cedar Cove, #1)', '1776', '1919', '1984', '1Q84', '1Q84 #1-2 (1Q84, #1-2)', '1Q84 BOOK 1 (1Q84, #1)', '1Q84 BOOK 2 (1Q84, #2)', '1Q84 BOOK 3 (1Q84, #3)', \"1st to Die (Women's Murder Club, #1)\", '2 States: The Story of My Marriage', '2 ضباط', '2001: A Space Odyssey (Space Odyssey, #1)', '2010: Odyssey Two (Space Odyssey, #2)', '204 Rosewood Lane (Cedar Cove, #2)', '206 Bones (Temperance Brennan, #12)', '2061: Odyssey Three (Space Odyssey, #3)', '20th Century Ghosts', '2312', '2666', '28 حرف', '2BR02B', \"2nd Chance (Women's Murder Club, #2)\", '30 Days of Night, Vol. 1']\n",
      "['Black Beauty', 'Black Bird, Vol. 01 (Black Bird, #1)', 'Black Boy', 'Black Butler, Vol. 1 (Black Butler, #1)', 'Black Butler, Vol. 2 (Black Butler, #2)', 'Black Butler, Vol. 3 (Black Butler, #3)', 'Black Cat, Volume 01', 'Black Cherry Blues (Dave Robicheaux, #3)', 'Black Dawn (The Morganville Vampires, #12)', 'Black Elk Speaks: Being the Life Story of a Holy Man of the Oglala Sioux', 'Black Hawk Down', 'Black Hills', 'Black Hole', 'Black Holes and Baby Universes', 'Black House (The Talisman, #2)', 'Black Ice', 'Black Lies', 'Black Like Me', 'Black List (Scot Harvath, #11)', 'Black Magic Sanction (The Hollows, #8)', 'Black Notice (Kay Scarpetta, #10)', 'Black Order (Sigma Force, #3)', 'Black Powder War (Temeraire, #3)', 'Black Rose (In the Garden, #2)', 'Black Sun Rising (The Coldfire Trilogy, #1)', 'Black Swan Green', 'Black Water (Pendragon, #5)', 'Black and Blue', 'Black-Eyed Susans', 'Black: The Birth of Evil (The Circle, #1)', 'Blackberry Wine', 'Blackberry Winter', 'Blackmoore', 'Blackout (All Clear, #1)', 'Blackout (Newsflesh Trilogy, #3)', 'Blackout: Remembering the Things I Drank to Forget', 'Blackwood Farm (The Vampire Chronicles, #9)', 'Blameless (Parasol Protectorate, #3)', 'Blankets', 'Blaze', 'Bleach, Volume 01', 'Bleach, Volume 03', 'Bleach, Volume 15', 'Bleachers', 'Bleak House', 'Bless Me, Ultima', 'Blessings', 'Blind Willow, Sleeping Woman', 'Blindness', 'Blindsight (Firefall, #1)']\n"
     ]
    }
   ],
   "source": [
    "print(type(book_names))\n",
    "print(book_names[0:50])\n",
    "print(book_names[1000:1050])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06d49d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:40:29  |\n",
      "- - - - - - - - - - - - - - -\n",
      "\n",
      "y_train after onehotencoding of the 'ratings' column (first 15 rows are displayed)\n",
      "\n",
      "[[0 0 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:40:29  |\n",
      "- - - - - - - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PrintCurrentTime()\n",
    "\n",
    "#\"\"\"\n",
    "# One Hot Encoding the \"rating\" column\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2])], remainder='passthrough')\n",
    "x1 = ct.fit_transform(df_train)\n",
    "#print(\"\\ntype(x1) = \",type(x1),\"shape= \",x1.shape,\"x1 is df_train after OneHotEncoder for rating column\")\n",
    "\n",
    "#x2 = np.array(x1)\n",
    "#print(\"\\ntype(x2) = \",type(x2),\"shape= \",x1.shape)\n",
    "#print(x2[:15])\n",
    "x2 = x1.astype(np.int32)\n",
    "#print(\"\\ntype(x2) = \",type(x2),\"shape= \",x1.shape, \"x2 is x1 just converting to integer types\")\n",
    "#print(\"First 5 columns are 'rating', then user_id, then book_id\")\n",
    "#print(x2[:15])\n",
    "\n",
    "x_hotencode = x2[:,0:5]\n",
    "#print(\"\\ntype(x_hotencode) = \",type(x_hotencode),\"shape= \",x1.shape)\n",
    "print(\"\\ny_train after onehotencoding of the 'ratings' column (first 15 rows are displayed)\\n\")\n",
    "print(x_hotencode[:15])\n",
    "\n",
    "\n",
    "\n",
    "PrintCurrentTime()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe437072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:40:30  |\n",
      "- - - - - - - - - - - - - - -\n",
      "Epoch 1/5\n",
      "3876/3876 [==============================] - 5s 1ms/step - loss: 1.3266 - accuracy: 0.3601 - val_loss: 1.3240 - val_accuracy: 0.3602\n",
      "Epoch 2/5\n",
      "3876/3876 [==============================] - 6s 1ms/step - loss: 1.3245 - accuracy: 0.3606 - val_loss: 1.3238 - val_accuracy: 0.3603\n",
      "Epoch 3/5\n",
      "3876/3876 [==============================] - 5s 1ms/step - loss: 1.3244 - accuracy: 0.3607 - val_loss: 1.3239 - val_accuracy: 0.3597\n",
      "Epoch 4/5\n",
      "3876/3876 [==============================] - 6s 1ms/step - loss: 1.3244 - accuracy: 0.3606 - val_loss: 1.3239 - val_accuracy: 0.3600\n",
      "Epoch 5/5\n",
      "3876/3876 [==============================] - 6s 1ms/step - loss: 1.3243 - accuracy: 0.3608 - val_loss: 1.3237 - val_accuracy: 0.3613\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:40:58  |\n",
      "- - - - - - - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------#\n",
    "PrintCurrentTime()\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 5\n",
    "validation_split = 0.1\n",
    "\n",
    "myModel.fit(data_feed_into_ann_values_scaled, x_hotencode,\n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs,\n",
    "            validation_split=validation_split,\n",
    "            verbose=1)\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "PrintCurrentTime()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b48121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SavedModels\\assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#pickle.dump(myModel, open(\"MyPicklefile\", 'wb'))\n",
    "# Get error 'cannot pickle '_thread.RLock' object'\n",
    "\n",
    "#loaded_model = pickle.load(open(MyPicklefile, 'rb'))\n",
    "\n",
    "# Use keras to save the model to folder 'SavedModels'\n",
    "# It created file 'saved_model.pb' and also two subfolders 'assets' and 'variables'\n",
    "myModel.save(\"SavedModels\")\n",
    "#sc.save(\"my_sc.p\")\n",
    "pickle.dump(sc, open(\"my_sc.p\", 'wb'))\n",
    "pickle.dump(book_names, open(\"my_book_names.p\", 'wb'))\n",
    "pickle.dump(rev_di_book_title, open(\"my_rev_di_book_title.p\", 'wb'))\n",
    "pickle.dump(book_id_mapping, open(\"my_book_id_mapping.p\", 'wb'))\n",
    "pickle.dump(user_id_mapping, open(\"my_user_id_mapping.p\", 'wb'))\n",
    "\n",
    "#myModel = \"hey-hey\"  # just set it to some dummie value\n",
    "\n",
    "#myModel = keras.models.load_model(\"SavedModels\")  #WORKS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c01f4abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data that will get fed into the 'predict' method\n",
      "first column is the scaled 'user_id', while second column is scaled 'book_id'\n",
      "[[ 1.64972196  0.63688379]\n",
      " [-0.46396415  2.32600679]\n",
      " [ 0.52285813  0.32003888]\n",
      " ...\n",
      " [-0.52207467 -0.95292962]\n",
      " [ 0.84981385 -0.23626684]\n",
      " [-1.05092842  1.26799414]]\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:41:02  |\n",
      "- - - - - - - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------#\n",
    "# Now repeat exactly what we did to prepare the data (i.e. the train data) \n",
    "# that gets fed into the ANN, but now do it for the test data\n",
    "\n",
    "test_user_data = df_test['user_id'].map(user_id_mapping)\n",
    "test_book_data = df_test['book_id'].map(book_id_mapping)\n",
    "\n",
    "test_data_feed_into_ann = pd.DataFrame({\"user_id\":test_user_data,\"book_id\":test_book_data})\n",
    "test_data_feed_into_ann_values = test_data_feed_into_ann.values\n",
    "\n",
    "test_data_feed_into_ann_values_scaled = sc.transform(test_data_feed_into_ann_values)\n",
    "\n",
    "print(\"test data that will get fed into the 'predict' method\")\n",
    "print(\"first column is the scaled 'user_id', while second column is scaled 'book_id'\")\n",
    "print(test_data_feed_into_ann_values_scaled)\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "PrintCurrentTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1bd7479f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 3129 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002D79CB994C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "y_pred follows:type(y_pred)= <class 'numpy.ndarray'>\n",
      "Each prediction consists of 5 probabilities\n",
      "[[0.01745463 0.0605141  0.24508111 0.36896268 0.30798742]\n",
      " [0.01768521 0.06099328 0.25550786 0.36669752 0.2991161 ]\n",
      " [0.01936655 0.06236345 0.2491574  0.36416897 0.30494365]\n",
      " ...\n",
      " [0.0239382  0.06036066 0.22266977 0.3482039  0.3448275 ]\n",
      " [0.01985889 0.06323113 0.2462273  0.36292318 0.30775946]\n",
      " [0.0179888  0.06108334 0.25308672 0.36558148 0.30225962]]\n",
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:41:06  |\n",
      "- - - - - - - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "y_pred = myModel.predict(test_data_feed_into_ann_values_scaled)\n",
    "#y_pred = list(map(lambda x: 1.0 if x < 1 else 5.0 if x > 5.0 else x, y_pred))\n",
    "\n",
    "print(\"\\ny_pred follows:type(y_pred)=\",type(y_pred))\n",
    "print(\"Each prediction consists of 5 probabilities\")\n",
    "print(y_pred)\n",
    "\n",
    "def GetWeightedValue(arr):\n",
    "    weighted_sum = 0.0\n",
    "    for idx in range(len(arr)):\n",
    "        rating = idx + 1\n",
    "        weighted_sum = weighted_sum + rating * arr[idx]\n",
    "    return weighted_sum\n",
    "\n",
    "y_pred_arr = []\n",
    "        \n",
    "for i in range(len(y_pred)):\n",
    "    wt_sum = GetWeightedValue(y_pred[i])\n",
    "    y_pred_arr.append(wt_sum)\n",
    "\n",
    "y_pred_arr = np.array(y_pred_arr)\n",
    "\n",
    "# get true labels\n",
    "y_true = df_test['rating'].values\n",
    "\n",
    "PrintCurrentTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42f6e0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing Result: 0.9889 RMSE\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "['The Regulators', 'The Strange Library', 'Gone for Good', 'A Light in the Attic', 'Into Thin Air: A Personal Acco']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "First 20 rows of results_df\n",
      "\n",
      "    User ID  Book ID                       Book Name  Predicted  Actual\n",
      "0      7966     2352                  The Regulators       3.89       3\n",
      "1     39399     4516             The Strange Library       3.87       4\n",
      "2     44001     3277                   Gone for Good       3.87       5\n",
      "3     44987      278            A Light in the Attic       3.91       5\n",
      "4      2860      236  Into Thin Air: A Personal Acco       3.91       4\n",
      "5     27767     1168                 The Tao of Pooh       3.96       4\n",
      "6     47869     1096  America (The Book): A Citizen'       3.86       3\n",
      "7     48414     9042                     The Painter       3.87       3\n",
      "8     41754      615                    This Lullaby       3.93       5\n",
      "9     47839     3020  The Metamorphosis and Other St       3.87       3\n",
      "10    38922      124                            Room       3.91       5\n",
      "11    48153      106                      Bossypants       3.97       5\n",
      "12    22667     3815  Wheat Belly: Lose the Wheat, L       3.87       4\n",
      "13     3222      467  The Brief Wondrous Life of Osc       3.86       4\n",
      "14    30711     3743             The Grouchy Ladybug       3.86       5\n",
      "15    11955       45                      Life of Pi       3.94       3\n",
      "16    25555     1767           The Sky Is Everywhere       3.87       3\n",
      "17    44977      494              The Secret History       3.86       4\n",
      "18     1624     5049   Dragondrums (Harper Hall, #3)       3.88       4\n",
      "19    41968       62  The Golden Compass (His Dark M       3.90       3\n",
      "\n",
      "Random sample of 25 rows of results_df\n",
      "\n",
      "       User ID  Book ID                       Book Name  Predicted  Actual\n",
      "12418    49035       56    Breaking Dawn (Twilight, #4)       3.90       3\n",
      "3817      3189      970  Steelheart (The Reckoners, #1)       3.87       4\n",
      "64306    29070      159  The Battle of the Labyrinth (P       3.91       3\n",
      "234      46744       18  Harry Potter and the Prisoner        3.92       5\n",
      "34297    23346       41  The Lightning Thief (Percy Jac       3.89       4\n",
      "9461     44538     7224      Knight & Play (Knight, #1)       3.87       5\n",
      "19260     9427      287                The Fountainhead       3.94       5\n",
      "69817    22215       22                The Lovely Bones       3.91       5\n",
      "53416    30656     6387  The Forbidden Game (The Forbid       3.87       2\n",
      "38990    14427     1801  The Sword of Shannara (The Ori       3.87       5\n",
      "49208    24705     6885                  Geisha, a Life       3.87       1\n",
      "5051     32964     4333  The Red Badge of Courage and S       3.87       4\n",
      "34299    11685       17  Catching Fire (The Hunger Game       3.91       3\n",
      "24109    35364     2226  The Demon-Haunted World: Scien       3.90       4\n",
      "8531     17700     2491  Heretics of Dune (Dune Chronic       3.87       3\n",
      "94474    17476      225                    East of Eden       3.87       5\n",
      "83721    13806     1031                A Moveable Feast       3.87       3\n",
      "54913    16603     5063     Up to Me (The Bad Boys, #2)       3.87       4\n",
      "80707    37345       10             Pride and Prejudice       3.93       5\n",
      "64407    41289      958  The Complete Anne of Green Gab       3.89       5\n",
      "28447    12674      422  Harry Potter Boxset (Harry Pot       3.88       5\n",
      "825       4264      246     Marked (House of Night, #1)       3.87       3\n",
      "78578    19082     3671                The Charm School       3.87       4\n",
      "72573     8356      126       Dune (Dune Chronicles #1)       3.90       4\n",
      "81123    46369     5050     The Story of Beautiful Girl       3.87       5\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:41:09  |\n",
      "- - - - - - - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Test model by making predictions on test data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_pred=y_pred_arr, y_true=y_true))\n",
    "print('\\n\\nTesting Result: {:.4f} RMSE'.format(rmse))\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "#print(\"test_user_data stuff follows:\", type(test_user_data))\n",
    "#print(test_user_data)\n",
    "#print(test_user_data.values)\n",
    "\n",
    "#print(\"\\n\\ntest_book_data stuff follows:\", type(test_book_data))\n",
    "#print(test_book_data)\n",
    "#print(test_book_data.values)\n",
    "\n",
    "y_pred_temp = np.round(y_pred_arr, 2)\n",
    "\n",
    "# go back to the original user id\n",
    "orig_user_id = [rev_user_id_mapping[test_user_data.values[i]] for i in range(len(test_user_data.values))]\n",
    "\n",
    "# go back to the original book id\n",
    "orig_book_id = [rev_book_id_mapping[test_book_data.values[i]] for i in range(len(test_book_data.values))]\n",
    "\n",
    "\n",
    "vals = test_book_data.values\n",
    "test_book_names = [di_book_title[orig_book_id[i]][0:30] for i in range(len(orig_book_id))]\n",
    "    \n",
    "print(test_book_names[:5])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'User ID': orig_user_id,\n",
    "    'Book ID': orig_book_id,\n",
    "    'Book Name': test_book_names,    \n",
    "    'Predicted': y_pred_temp,\n",
    "    'Actual': y_true\n",
    "})\n",
    "\n",
    "print(\"\\nFirst 20 rows of results_df\\n\")\n",
    "print(results_df.head(20))\n",
    "print(\"\\nRandom sample of 25 rows of results_df\\n\")\n",
    "print(results_df.sample(25))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "PrintCurrentTime()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a272e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Chamber of Secrets (Harry Potter, #2)\n",
      "The 8th Confession (Women's Murder Club, #8)\n"
     ]
    }
   ],
   "source": [
    "print(di_book_title[23])\n",
    "print(di_book_title[3517])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca42d78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[689]\n",
      "[2057]\n",
      "The Litigators\n",
      "2057\n",
      "Number of User ID:  36199 Number of Book ID:  9466\n",
      "6466\n",
      "nope\n",
      "yep\n",
      "book id for book The Wise Man's Fear (The Kingkiller Chronicle, #2) =  307\n"
     ]
    }
   ],
   "source": [
    "# Test using user_id = 9106 and book_id 136\n",
    "test_user_data = [user_id_mapping[9106]]\n",
    "test_book_data = [book_id_mapping[136]]\n",
    "print(test_user_data)\n",
    "print(test_book_data)\n",
    "print(di_book_title[book_id_mapping[136]])\n",
    "print(rev_di_book_title[di_book_title[book_id_mapping[136]]])\n",
    "\n",
    "number_of_user_id = len(user_id_mapping)\n",
    "number_of_book_id = len(book_id_mapping)\n",
    "print(\"Number of User ID: \",number_of_user_id, \"Number of Book ID: \",number_of_book_id)\n",
    "print(rev_user_id_mapping[35])\n",
    "\n",
    "myS = \"U R D Man\"\n",
    "if myS in rev_di_book_title:\n",
    "    print(\"yep\")\n",
    "else:\n",
    "    print(\"nope\")\n",
    "myS = \"The Wise Man's Fear (The Kingkiller Chronicle, #2)\"\n",
    "if myS in rev_di_book_title:\n",
    "    print(\"yep\")\n",
    "    print(f\"book id for book {myS} = \",rev_di_book_title[myS])\n",
    "else:\n",
    "    print(\"nope\")\n",
    "\n",
    "# Note to self: The # of user-id is from 0 to 36198, but to \"track\" that back \n",
    "# to the DB, need to look at rev_user_id_mapping.\n",
    "# By way of an example, although id = 35 (prior to scaling of course) may be fed into the ANN,\n",
    "# it may NOT appear in the DB!  What does appear in the DB is rev_user_id_mapping[35], \n",
    "# which turns out to be 36705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0252f272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4513]\n",
      "[4169]\n",
      "test data that will get fed into the 'predict' method\n",
      "first column is the scaled 'user_id', while second column is scaled 'book_id'\n",
      "[[-1.28577176  0.75381977]]\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:41:18  |\n",
      "- - - - - - - - - - - - - - -\n",
      "\n",
      "y_pred follows:type(y_pred)= <class 'numpy.ndarray'>\n",
      "Each prediction consists of 5 probabilities\n",
      "[[0.01904849 0.06266943 0.2519381  0.36317402 0.30317003]]\n",
      "Prediction:  [3.86874789]\n",
      "\n",
      "- - - - - - - - - - - - - - -\n",
      "| Current Time =  13:41:18  |\n",
      "- - - - - - - - - - - - - - -\n"
     ]
    }
   ],
   "source": [
    "# Now do what we did for the TruncatedSVD project.\n",
    "# That is let someone pick a \"user_id/book_id\" pair and we tell them how this user_id \n",
    "# would rate this particular book_id\n",
    "\n",
    "# 36828     5010      Inca Gold (Dirk Pitt, #12) 3.89\n",
    "\n",
    "# Test using user_id = 9106 and book_id 136\n",
    "# First, what are the valid user_id?\n",
    "number_of_user_id = len(user_id_mapping)\n",
    "actual_uid = 36828\n",
    "uid = user_id_mapping[actual_uid]\n",
    "actual_bid = 5010\n",
    "number_of_book_id = len(book_id_mapping)\n",
    "bid = book_id_mapping[actual_bid]\n",
    "\n",
    "test_user_data = [uid]\n",
    "test_book_data = [bid]\n",
    "print(test_user_data)\n",
    "print(test_book_data)\n",
    "\n",
    "\n",
    "test_data_feed_into_ann = pd.DataFrame({\"user_id\":test_user_data,\"book_id\":test_book_data})\n",
    "test_data_feed_into_ann_values = test_data_feed_into_ann.values\n",
    "\n",
    "test_data_feed_into_ann_values_scaled = sc.transform(test_data_feed_into_ann_values)\n",
    "\n",
    "print(\"test data that will get fed into the 'predict' method\")\n",
    "print(\"first column is the scaled 'user_id', while second column is scaled 'book_id'\")\n",
    "print(test_data_feed_into_ann_values_scaled)\n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "PrintCurrentTime()\n",
    "\n",
    "# get the rating for this book\n",
    "y_pred = myModel.predict(test_data_feed_into_ann_values_scaled)\n",
    "#y_pred = list(map(lambda x: 1.0 if x < 1 else 5.0 if x > 5.0 else x, y_pred))\n",
    "\n",
    "print(\"\\ny_pred follows:type(y_pred)=\",type(y_pred))\n",
    "print(\"Each prediction consists of 5 probabilities\")\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_arr = []\n",
    "        \n",
    "for i in range(len(y_pred)):\n",
    "    wt_sum = GetWeightedValue(y_pred[i])\n",
    "    y_pred_arr.append(wt_sum)\n",
    "\n",
    "y_pred_arr = np.array(y_pred_arr)\n",
    "\n",
    "print(\"Prediction: \",y_pred_arr)\n",
    "\n",
    "PrintCurrentTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9283affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort a list of tuples on the 2nd element\n",
    "def Sort_Tuple(tup): \n",
    "  \n",
    "    # reverse = None (Sorts in Ascending order) \n",
    "    # key is set to sort using second element of \n",
    "    # sublist lambda has been used \n",
    "    tup.sort(key = lambda x: x[1],reverse = False) \n",
    "    #tup.sort(key=sortSecond,reverse = False)\n",
    "    return tup \n",
    "\n",
    "# book_name ==> index into book_names list\n",
    "def get_index_for_book(book_name):\n",
    "    for i in range(num_books_in_list):\n",
    "        if book_names[i] == book_name:\n",
    "            return i\n",
    "\n",
    "    return -1\n",
    "\n",
    "# book_name ==> ordered list of tuples, with descending\n",
    "# values of cosine-similarity (each ordered tuple is of the form\n",
    "# (book name,cos-sim value)\n",
    "def get_ordered_list_for_book(book_name):\n",
    "    ordered_list = []\n",
    "    idx = get_index_for_book(book_name)\n",
    "    if (idx < 0):\n",
    "        return ordered_list\n",
    "    unordered_list = [(book_names[i],corr_mat[idx,i]) for i in range(len(book_names))]\n",
    "    \n",
    "    ordered_list = Sort_Tuple(unordered_list)\n",
    "\n",
    "    return ordered_list\n",
    "\n",
    "# book_name ==> index of a book in book_names that is closest\n",
    "# to book_name\n",
    "def get_first_index_closes_to_name(book_name):\n",
    "    short = book_name[0:7].upper()\n",
    "    for idx in range(len(book_names)):\n",
    "        if book_names[idx][0:7].upper().find(short) >= 0:\n",
    "            return idx\n",
    "\n",
    "    short = book_name[0:6].upper()\n",
    "    for idx in range(len(book_names)):\n",
    "        if book_names[idx][0:6].upper().find(short) >= 0:\n",
    "            return idx\n",
    "\n",
    "    short = book_name[0:5].upper()\n",
    "    for idx in range(len(book_names)):\n",
    "        if book_names[idx][0:5].upper().find(short) >= 0:\n",
    "            return idx\n",
    "\n",
    "    short = book_name[0:4].upper()\n",
    "    for idx in range(len(book_names)):\n",
    "        if book_names[idx][0:4].upper().find(short) >= 0:\n",
    "            return idx\n",
    "\n",
    "    short = book_name[0:3].upper()\n",
    "    for idx in range(len(book_names)):\n",
    "        if book_names[idx][0:3].upper().find(short) >= 0:\n",
    "            return idx\n",
    "\n",
    "    short = book_name[0:2].upper()\n",
    "    for idx in range(len(book_names)):\n",
    "        if book_names[idx][0:2].upper().find(short) >= 0:\n",
    "            return idx\n",
    "\n",
    "    short = book_name[0:1].upper()\n",
    "    for idx in range(len(book_names)):\n",
    "        if book_names[idx][0:1].upper().find(short) >= 0:\n",
    "            return idx\n",
    "\n",
    "    \n",
    "    return -1\n",
    "\n",
    "# book_name ==> get list of 20 books that are before book_name and\n",
    "# 20 books that are after book_name\n",
    "def get_books_close_by_in_name(book_name):\n",
    "    idx = get_first_index_closes_to_name(book_name)\n",
    "    the_list = []\n",
    "    if idx < 0:\n",
    "        return the_list\n",
    "    \n",
    "    lower = idx - int(max_books_to_display/2)\n",
    "    if lower < 0:\n",
    "        lower = 0\n",
    "    higher = idx + int(max_books_to_display/2)\n",
    "    if higher >= num_books_in_list:\n",
    "        higher = num_books_in_list - 1\n",
    "    for i in range(lower,higher):\n",
    "        the_list.append(book_names[i])\n",
    "\n",
    "    return the_list\n",
    "\n",
    "def GetUserPredRatingOfBook(uid,bid):\n",
    "    # I'm trying to be consistent - when I write uid or user_id I mean the \n",
    "    # user id in the DB, while user_index is what user_id gets mapped to \n",
    "    # (i.e. consecutive numbers from 0 thru 36198).\n",
    "    # Same for bid - this is the number that appears in the DB, while book_index \n",
    "    # is what bid gets mapped to (i.e. consecutive numbers from 0 to 9465)\n",
    "    test_user_data = [uid]\n",
    "    test_book_data = [bid]\n",
    "\n",
    "\n",
    "    test_data_feed_into_ann = pd.DataFrame({\"user_id\":test_user_data,\"book_id\":test_book_data})\n",
    "    test_data_feed_into_ann_values = test_data_feed_into_ann.values\n",
    "\n",
    "    test_data_feed_into_ann_values_scaled = sc.transform(test_data_feed_into_ann_values)\n",
    "\n",
    "    # get the rating for this book\n",
    "    y_pred = myModel.predict(test_data_feed_into_ann_values_scaled)\n",
    "\n",
    "    wt_sum = GetWeightedValue(y_pred[0])\n",
    "    return wt_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3402c7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "1. Enter '1' to enter a user_id and bookname in order to get predicted rating\n",
      "2. Enter '2' to see if a book is in the list\n",
      "3. Enter '3' to quit\n",
      "\n",
      "Enter 1, 2, or 3: 1\n",
      "\n",
      "\n",
      "\n",
      "Enter a user index (0 thru 36198): 149\n",
      "\n",
      "Enter a book name: Are you ok\n",
      "\n",
      "The book name you entered 'Are you ok' is not in our database\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "1. Enter '1' to enter a user_id and bookname in order to get predicted rating\n",
      "2. Enter '2' to see if a book is in the list\n",
      "3. Enter '3' to quit\n",
      "\n",
      "Enter 1, 2, or 3: 2\n",
      "\n",
      "\n",
      "\n",
      "Enter book title to search for: Are You ok\n",
      "\n",
      "The book 'Are You ok' is NOT in our database, here are books that are close-by\n",
      "\n",
      "Appointment with Death (Hercule Poirot, #19)\n",
      "April 1865: The Month That Saved America\n",
      "Apt Pupil\n",
      "Arcadia\n",
      "Arcadia\n",
      "Arch of Triumph: A Novel of a Man Without a Country\n",
      "Archangel's Blade (Guild Hunter, #4)\n",
      "Archangel's Consort (Guild Hunter, #3)\n",
      "Archangel's Kiss (Guild Hunter, #2)\n",
      "Archer's Voice\n",
      "Are You Afraid of the Dark?\n",
      "Are You My Mother?\n",
      "Are You My Mother?\n",
      "Are You There God? It's Me, Margaret\n",
      "Are You There, Vodka? It's Me, Chelsea\n",
      "Area 7 (Shane Schofield, #2)\n",
      "Ariel\n",
      "Aristotle and Dante Discover the Secrets of the Universe (Aristotle and Dante Discover the Secrets of the Universe, #1)\n",
      "Ark Angel (Alex Rider, #6)\n",
      "Armada\n",
      "---------------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "1. Enter '1' to enter a user_id and bookname in order to get predicted rating\n",
      "2. Enter '2' to see if a book is in the list\n",
      "3. Enter '3' to quit\n",
      "\n",
      "Enter 1, 2, or 3: 1\n",
      "\n",
      "\n",
      "\n",
      "Enter a user index (0 thru 36198): 149\n",
      "\n",
      "Enter a book name: Are You Afraid of the Dark?\n",
      "\n",
      "\n",
      "User Index: 149 (user id: 4513), book: 'Are You Afraid of the Dark?' (book id: 3760), Predicted Rating: 3.880\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "1. Enter '1' to enter a user_id and bookname in order to get predicted rating\n",
      "2. Enter '2' to see if a book is in the list\n",
      "3. Enter '3' to quit\n",
      "\n",
      "Enter 1, 2, or 3: 3\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Test using 'saved off files'\n",
    "myModel = keras.models.load_model(\"SavedModels\")\n",
    "\n",
    "sc = pickle.load( open( \"my_sc.p\", \"rb\" ) )\n",
    "book_names = pickle.load( open( \"my_book_names.p\", \"rb\" ) )\n",
    "rev_di_book_title = pickle.load( open( \"my_rev_di_book_title.p\", \"rb\" ) )\n",
    "book_id_mapping = pickle.load( open( \"my_book_id_mapping.p\", \"rb\" ) )\n",
    "user_id_mapping = pickle.load(open(\"my_user_id_mapping.p\", 'rb'))\n",
    "\n",
    "\n",
    "max_books_to_display = 20\n",
    "num_books_in_list = len(book_names)\n",
    "\n",
    "def GetMainMenuOption():\n",
    "    print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\n\")\n",
    "    print(\"1. Enter '1' to enter a user_id and bookname in order to get predicted rating\")\n",
    "    print(\"2. Enter '2' to see if a book is in the list\")\n",
    "    print(\"3. Enter '3' to quit\")\n",
    "    answer = int(input(\"\\nEnter 1, 2, or 3: \"))\n",
    "    if answer < 1 or answer > 3:\n",
    "        answer = 3\n",
    "    return answer\n",
    "\n",
    "    \n",
    "\n",
    "answer = GetMainMenuOption()\n",
    "while answer != 3:\n",
    "    if answer == 1:\n",
    "        print(\"\\n\")\n",
    "        user_index = int(input(f\"\\nEnter a user index (0 thru {number_of_user_id-1}): \"))\n",
    "        book_name = input(f\"\\nEnter a book name: \");\n",
    "        if (user_index >= 0) and (user_index < number_of_user_id) and (book_name in rev_di_book_title):\n",
    "            #uid = rev_user_id_mapping[user_index]\n",
    "            book_id = rev_di_book_title[book_name]\n",
    "            book_index = book_id_mapping[book_id]\n",
    "            \n",
    "            pred_rating = GetUserPredRatingOfBook(user_index,book_index)          \n",
    "\n",
    "            print(f\"\\n\\nUser Index: {user_index} (user id: {uid}), book: '{book_name}' (book id: {book_id}), Predicted Rating: {pred_rating:.3f}\")                    \n",
    "        else:\n",
    "            if user_index < 0:\n",
    "                print(\"\\nuser index must be >= 0\")\n",
    "            elif user_index >= number_of_user_id:\n",
    "                print(f\"\\nuser index must be <= {number_of_user_id-1}\")\n",
    "            else:\n",
    "                print(f\"\\nThe book name you entered '{book_name}' is not in our database\")\n",
    "\n",
    "                \n",
    "    elif answer == 2:\n",
    "        print(\"\\n\")\n",
    "        title = input(\"\\nEnter book title to search for: \")\n",
    "        if title in rev_di_book_title:\n",
    "            print(f\"\\nbook title '{title}' is in our database\")\n",
    "        else:\n",
    "            the_list = get_books_close_by_in_name(title)\n",
    "            print(f\"\\nThe book '{title}' is NOT in our database, here are books that are close-by\\n\")\n",
    "            for i in range(len(the_list)):\n",
    "                print(the_list[i])\n",
    "            print(\"---------------------\")\n",
    "    \n",
    "    answer = GetMainMenuOption()           \n",
    "    \n",
    "\n",
    "print(\"\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\n\")\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb588341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
